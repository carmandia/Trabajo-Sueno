---
title: "Estudio de enfermedades del sueño"
output: 
  flexdashboard::flex_dashboard
runtime: shiny
---
```{r setup,include=FALSE}
library(flexdashboard)
library(shinydashboard)
```

# Introducción

<h1>Motivación del trabajo</h1>

El trabajo se basa en un fichero **csv** extraído del sitio web *KAGGLE* llamado **"sleep_health_lifestyle_dataset.csv"**. El fichero de datos consta de varias columnas, las cuales analizaremos en profundidad más adelante, y entre las que consta una variable llamada *Sleep Disorder* en la que veremos si el paciente presenta insomnio, apnea del suño, o no presenta ninguna enfermedad. El resto de variables como pueden ser la ocupación laboral del paciente, su sexo, índice de masa corporal, u otros parámetros como los pasos diarios, la presión arterial, las usaremos para en un primer lugar ver que tipo de relación tienen con la variable objetivo *Sleep Disorder*, como cual es la que mas le influye, y posteriormente para construir modelos intentando predecir de la mejor manera si los pacientes presentan o no una enfermedad del sueño.

```{r,warning=FALSE,include=FALSE}
library(tidyverse)
library(dplyr)
library(readr)
library(magrittr)
#library(tidymodels)
library(themis)
library(reticulate)
```

```{r global_options, echo=FALSE,cache=FALSE}
knitr::opts_chunk$set(fig.width = NULL, fig.height = NULL)
```


# Lectura y visualización inicial {data-navmenu="Tratamiento inicial"}

Comienzo con la lectura de los datos desde el fichero csv:

```{r,echo=F}
datos <- read_csv("sleep_health_lifestyle_dataset.csv")
```

A continuación pasaremos a una visualización del DataFrame para hacernos un poco la idea  las distintas variables que tiene, que trabajo tendremos que acometer a lo largo del proyecto en cuestión de depuración de datos si hiciera falta, que representaciones gráficas pudieran resultar de interés.

```{r,echo=F}
head(datos)
```

Como podemos ver de un primer vistazo, nos encontramos con la primera columna que es un id, y por lo tanto podemos prescindir de el tanto para la visualización como para lo modelos. Posteriormente nos encontramos variables como genero y edad cuyo estudio puede ser interesante si mujeres u hombres sufren mas o menos enfermedades del sueño, o si estas se ven afectadas por la franja de edad donde se encuentre la persona. Luego una variable sobre el trabajo que desarrolla la persona que también resulta interesante para los mismos estudios que antes. Tras esto tenemos variables mas relacionadas con el sueño como el numero de horas que duerme la persona o la calidad del sueño que seguro serán muy importantes para la fase de los modelos. Continuando, nos encontramos con una variable, la presión sanguínea que vemos que en una misma variable agrupa dos informaciones, la presión baja y alta separadas por una barra, por lo que como depuración tendremos que separar esta variable en otras dos.

```{r,echo=F}
summary(datos)
```

De esta manera vemos el tipo de datos que tiene cada variable por si es necesario cambiarlo, junto con algunos datos interesantes de las variables.

# Depuración de los datos {data-navmenu="Tratamiento inicial" .storyboard}

### Eliminación variables que sobran

Continuamos con la adecuación de los datos que nos proporciona el DataFrame para poder representarlo gráficamente y construir modelos adecuadamente.

Nuestro primer paso, como comentamos nada mas visualizar los datos es eliminar la primera variable:

```{r, echo=TRUE}
datos %<>%
  select(-`Person ID`)
```

### Cambiar tipo de las variables

**Variable Gender**

Vemos los niveles de la variable género:

```{r,echo=F}
datos$Gender <- datos %$%
  Gender %>%
  map(.,as.factor) %>%
  unlist()
summary(datos$Gender)
```

 **Variable BMI Category**

Vemos los niveles de la variable índice de masa corporal:

```{r,echo=TRUE}
datos$`BMI Category` <- datos %$%
  `BMI Category` %>%
  as.factor()
summary(datos$`BMI Category`)
```

**Variable Occupation**

Vemos los niveles de la variable ocupación laboral:

```{r,echo=TRUE}
datos$Occupation <- datos %$%
  Occupation %>%
  as.factor()
summary(datos$Occupation)
```

**Variable Sleep Disorder**

Vemos los niveles de la variable objetivo desorden del sueño:

```{r,echo=TRUE}
datos$`Sleep Disorder` <- datos %$%
  `Sleep Disorder` %>%
  as.factor()
summary(datos$`Sleep Disorder`)
```

### Transformacion de la variable *Blood Pressure*

A continuación pasamos a cambiar la variable Blood Pressure. Como hemos comentado al comienzo, esta variable contiene la presión alta y baja en una sola y separada por la barra "/". Lo que haremos es dividir esta variable en otras dos que ya renombraremos separando por esa barra.

```{r,echo=TRUE}
# datos %$%
#   `Blood Pressure (systolic/diastolic)` %>%
#   str_split(.,pattern="/",simplify = T) 
```

Así tendríamos dividida la variable en dos columnas, una con la presión alta (la primera) y la otra con la presión baja. Pasamos a guardar cada una como variables y a eliminar esa variable que no nos sirve, haciendo todo el proceso de continuo. 

```{r,echo=TRUE}
Press_High <- datos %$%
  `Blood Pressure (systolic/diastolic)` %>%
  str_split(.,pattern="/",simplify = T) %>%
  .[,1] %>%
  as.numeric()
Press_Low <- datos %$%
  `Blood Pressure (systolic/diastolic)` %>%
  str_split(.,pattern="/",simplify = T) %>%
  .[,2] %>%
  as.numeric()
datos$Press_High <- Press_High
datos$Press_Low <- Press_Low
```

Ahora solo nos queda eliminar la columna que hemos transformado, y ver el resultado:

```{r,echo=F}
datos %<>%
  select(-`Blood Pressure (systolic/diastolic)`)
summary(datos)
```

De esta manera ya tenemos todas las variables de manera adecuada para la representación gráfica de estudios que nos interesen para una posterior construcción de modelos.

### Exportación de los datos

Antes de terminar exportamos en un fichero nuevo los datos depurados para posibles consultas. Recordamos que para exportarlos, los datos que están convertidos a factor debemos pasarlos a tipo *character*:

```{r,echo=TRUE}
datos2 <- datos %>%
  mutate(across(where(is.factor),as.character))
datos2[datos2$`Sleep Disorder`=="None","Sleep Disorder"]="No enfermedad"
write_csv(x = datos2,file = "Datos_depurados.csv",col_names = T)
```



# Presion Arterial (Alta y baja) {data-navmenu="Estudio de influencia en la variable objetivo"}

<h2>Influencia de la presión arterial</h2>
<div>
```{r,echo=F}
datos %>%
  ggplot(aes(Press_High,Press_Low,color=`Sleep Disorder`)) +
  geom_point()
```
</div>

En esta primera gráfica comparamos la presión alta y la presión baja en función del tipo de enfermedad del sueño que tenga la persona. Una vez hecha la representación no podemos inferir gran cosa a partir del gráfico, puesto que todas las enfermedades están mas o menos igualmente representadas para valores similares de presión arterial

<div>
```{r,echo=F}
datos %>%
  ggplot(aes(Press_High,Press_Low,color=`Sleep Disorder`)) +
  geom_point() +
  geom_smooth(aes(linetype = `Sleep Disorder`))
```
</div>

Como podemos observar las linea que interpola cada conjunto de puntos en función de la clase de enfermedad del sueño que tenga es muy similar. Y hay que recalcar que los intervalos de confianza se cortan por lo que podemos descartar que estas variables nos sirvan para identificar que tipo de enfermedad posee la persona.

# Pulsaciones por minuto {data-navmenu="Estudio de influencia en la variable objetivo"}

<h2>Influencia de las pulsaciones </h2>

<div>
```{r,echo=F}
datos %>%
  ggplot() +
  stat_summary(aes(`Sleep Disorder`,`Heart Rate (bpm)`),
               fun=median,
               fun.min = min,
               fun.max = max)
```
</div>

Al igual que en el caso anterior parece que vuelven a ser muy similares las pulsaciones independientemente de la enfermedad que presente el individuo. Lo único que podríamos destacar es que los individuos con apnea del sueño la tienen algo mas alta.
  


# Índice de masa corporal {data-navmenu="Estudio de influencia en la variable objetivo"}

<h2>Influencia del BMI</h2>

<div>

```{r}
datos %>%
  ggplot() +
  geom_bar(aes(x=`Sleep Disorder`,fill=`BMI Category`))
```
</div>

En esta gráfica si que parece que podemos sacar alguna que otra conclusión mas: en el caso de las personas que sufren insomnio, hay una mayor proporción de personas que están demasiado delgados; en el caso de las personas que no sufren ninguna enfermedad (que son la mayoría de ellas), parece que hay mayor proporción en personas que sufren sobrepeso. Por otro lado de las personas que sufren apnea del sueño parece que tienen igual proporción.



<div>    
```{r}
datos %>%
  ggplot() +
  geom_bar(aes(x=`Sleep Disorder`,fill=`BMI Category`),position = "dodge")
```
</div>

Con esta gráfica podemos ver mas claro el diagrama anterior. Se hace notar mas que las personas con un indice de masa normal están representadas en menor proporción en el conjunto de personas sin enfermedad del sueño

# Ocupación laboral y nivel de estrés {data-navmenu="Estudio de influencia en la variable objetivo"}
<h2>Influencia conjunta de ambas variables </h2>

<div>
```{r,echo=F}
datos %>%
  count(Occupation,`Stress Level (scale: 1-10)`,`Sleep Disorder`) %>%
  group_by(Occupation,`Sleep Disorder`) %>%
  mutate(Proportion = n/sum(n)) %>%
  ggplot(aes(`Stress Level (scale: 1-10)`,Proportion,fill=`Sleep Disorder`))+
  geom_col(position = 'dodge') + 
  scale_y_continuous(labels = scales::percent_format()) +
  facet_wrap(~Occupation,nrow = 2)
```

</div>

En este gráfico comparamos por la ocupación que tienen las personas y su enfermedad, o ausencia de ella, el nivel de estrés que dicen tener por si esto pudiera tener un comportamiento específico. Por ejemplo, para las personas que trabajan en labores manuales, los que sufren apnea del sueño son los que en mayor proporción tienen altos niveles de estrés. Lo mismo ocurre para el caso de los estudiantes, que en gran proporción los que dicen sufrir niveles altos de estrés sufren apnea del sueño. En cambio, las personas que sufren insomnio, en cualquier ocupación laboral, parece que se encuentran en mayor porcentaje en niveles de estrés bajos, mientras que las personas que no sufren ninguna enfermedad del sueño parecen estar repartidos los porcentajes entre los distintos niveles de estrés para cualquier ocupación.

# Actividad física y duración del sueño {data-navmenu="Estudio de influencia en la variable objetivo"}

<h2>Influencia conjunta de ambas variables </h2>

<div>
```{r,echo=F}
datos %>%
  ggplot(aes(`Sleep Duration (hours)`,`Quality of Sleep (scale: 1-10)`,color=`Sleep Disorder`)) +
  geom_point()
```
</div>

Volvemos a encontrarnos una situación en la que no podemos sacar demasiadas conclusiones puesto que no se observa un patrón en los datos. Lo mas reseñable es que la mayoría de puntos de personas con apnea del sueño tienen una calidad del sueño intermedio, ni valores muy altos ni muy bajos. Vamos a realizar una curva de regresión con su intervalo de confianza para asegurarnos de este patrón

<div>
```{r,echo=F}
datos %>%
  ggplot(aes(`Sleep Duration (hours)`,`Quality of Sleep (scale: 1-10)`,color=`Sleep Disorder`)) +
  geom_point() +
  geom_smooth(aes(linetype = `Sleep Disorder`))
```
</div>

Vemos que parece que estábamos en lo cierto que no podemos sacar conclusiones puesto que los tres intervalos de confianza se cortan y por tanto no podemos inferir que con una calidad del sueño mejor o pero o mas o menos horas de sueño pueda referirse a una persona con una determinada enfermedad del sueño.

# División y preparación del conjunto de datos {data-navmenu="Modelado de datos" }

A partir de este instante trabajamos con python.

```{python}
import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn import model_selection

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report,ConfusionMatrixDisplay
from sklearn.decomposition import PCA
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn import neighbors
from sklearn.neural_network import MLPClassifier
from sklearn.utils import resample
```

Leemos y vemos una breve descripción de los datos para ver que no ha habido ningún problema:

```{python}
datos2 = pd.read_csv('Datos_depurados.csv')
datos2.info()
```

En las anteriores secciones nos hemos dado cuenta que hay muchos mas pacientes sin enfermedad que con apnea o insomnio. Veamos en términos porcentuales:

```{python}
print(pd.Series(datos2["Sleep Disorder"]).value_counts(normalize=True))
```

Vamos a balancear los datos, puestos que la diferencia de cantidad de cada clase es demasiado grande, y tenemos pocos datos:

```{python}
no_enfermedad = datos2[datos2["Sleep Disorder"] == "No enfermedad"]
insomnio = datos2[datos2["Sleep Disorder"] == "Insomnia"]
sleep_apnea = datos2[datos2["Sleep Disorder"] == "Sleep Apnea"]

print(no_enfermedad.shape)
print(insomnio.shape)
print(sleep_apnea.shape)
```
Vemos cuantos datos hay, para cada uno de los niveles de la variable (no enfermedad, insomnio y apnea del sueño). Realizamos upsampling y vemos cuantos datos obtenemos al final:

```{python}
insomnio_upsample = resample(insomnio,replace=True,n_samples=len(no_enfermedad),random_state=47563)
sleep_apnea_upsample = resample(sleep_apnea,replace=True,n_samples=len(no_enfermedad),random_state=47563)
print(insomnio_upsample.shape)
print(sleep_apnea_upsample.shape)
```

Y ya solo concatenamos los datos creando nuestro dataset balanceado:

```{python}
datos_upsampled = pd.concat([no_enfermedad,insomnio_upsample,sleep_apnea_upsample])
print(pd.Series(datos_upsampled["Sleep Disorder"]).value_counts(normalize=True))
```

Vemos que ya tenemos el mismo numero de individuos en cada clase.

Dividimos los datos entre nuestra variable objetivo, y las que usamos de predictoras:

```{python}
predictoras = datos_upsampled.loc[:,datos_upsampled.columns != 'Sleep Disorder']
objetivo = datos_upsampled['Sleep Disorder']
```

Particionamos los datos en entrenamiento y test para la construcción de los modelos, teniendo en cuenta que tenemos que mantener esta proporción. Dejamos únicamente un 25% de los datos destinado al conjunto test.

```{python}
(predictoras_train,predictoras_test,objetivo_train,objetivo_test) = model_selection.train_test_split(predictoras,objetivo,random_state=47563, test_size=.25,stratify=objetivo)
```



Dividimos las variables predictoras en las que son numéricas y las que son categóricas:

```{python}
predictoras_train_num = predictoras_train.select_dtypes(include=['int64', 'float64'])
predictoras_train_cat = predictoras_train.select_dtypes(include='object')
predictoras_train_cat.info()
predictoras_train_num.info()
```
Ahora construimos nuestro *pipeline* para transformar los datos. Como en el apartado de visualización no hemos visto que haya ninguna variable que podamos decir que separa a nuestra variable objetivo hacemos un análisis en componentes principales, para ver si reduciendo la dimensionalidad de los datos lo obtenemos de una mejor manera:

```{python}
preprocesador = ColumnTransformer([('num', StandardScaler(), predictoras_train_num.columns.to_list()),('cat', OneHotEncoder(), predictoras_train_cat.columns.to_list()),])

pipeline = Pipeline([('preprocesado',preprocesador),('pca', PCA(n_components=2)),])

# Aplicar el pipeline
Conjunto_entrenamiento = pipeline.fit_transform(predictoras_train)
Conjunto_test = pipeline.transform(predictoras_test)
#print(Conjunto_entrenamiento)
#print(Conjunto_test)
```

Ya tenemos los conjuntos de entrenamiento y test listos para crear los modelos y ver el rendimiento de los mismos.

# Modelo Naive-Bayes {data-navmenu="Modelado de datos"}

## Columna {data-width=1}

### Modelo
Una vez construimos el modelo pasamos a ver su efectividad comparando el resultado de pasar el conjunto test por el modelo con el verdadero valor de la variable objetivo:

```{python}
clasif_NB = GaussianNB()
clasif_NB.fit(Conjunto_entrenamiento,objetivo_train)
objetivo_predicho_NB = clasif_NB.predict(Conjunto_test)
```

## Columna {data-width=2 .tabset}

### Métricas del modelo

```{python}
print(classification_report(objetivo_test,objetivo_predicho_NB,target_names=np.unique(objetivo_test)))
```

### Matriz de confusión
```{python}
ConfusionMatrixDisplay.from_estimator(clasif_NB,Conjunto_test,objetivo_test,display_labels=np.unique(objetivo_test),cmap="Blues")
plt.title("Matriz de Confusión: Método NB")
plt.show()
```

### Frontera de separación
```{python}
def grafica_frontera_decision(modelo,predictoras,test,titulo):
  h=.02
  x_min,x_max = predictoras[:,0].min() - .5, predictoras[:,0].max() + .5
  y_min,y_max = predictoras[:,1].min() - .5, predictoras[:,1].max() + .5
  xx,yy = np.meshgrid(np.arange(x_min,x_max,h),np.arange(y_min,y_max,h))
  Z=modelo.predict(np.c_[xx.ravel(),yy.ravel()])
  Z=Z.reshape(xx.shape)
  plt.figure(figsize=(8,6))
  for i in range(len(Z)):
    for j in range(len(Z[i])):
      if Z[i][j] == "No enfermedad":
        Z[i][j] = 0
      elif Z[i][j] == "Sleep apnea":
        Z[i][j] = 1
      else:
        Z[i][j] = 2
  Z = Z.astype(int)
  plt.contourf(xx,yy,Z,cmap=plt.cm.Pastel1,alpha=0.8)
  sns.scatterplot(x=predictoras[:, 0], y=predictoras[:, 1], hue=test, palette="Set2", s=70, edgecolor="k")
  plt.xlabel("Componente Principal 1")
  plt.ylabel("Componente Principal 2")
  plt.title(titulo)
  plt.legend(title="Clase")
  plt.grid(True)
  plt.tight_layout()
  plt.show()

```

```{python}
grafica_frontera_decision(clasif_NB,Conjunto_test,objetivo_test,"Frontera decision NB")
```


## Columna {data-width=1}

### Conclusiones
Podemos ver que el rendimiento de nuestro modelo es en general malo, pues no detecta de manera correcta ninguno de los niveles. Viendo representada la matriz de confusión, como sospechábamos no suele clasificar bien a los sujetos, tiene poca precisión. Representando la frontera de decisión vemos que con este modelo no conseguimos separar bien los datos.

# Modelo Random forest {data-navmenu="Modelado de datos"}

## Columna {data-width=1}

### Modelo
Aplicamos una malla para hallar los mejores hiperparámetros:
```{python}
rejilla_parametros =[{'n_estimators':[3,5,7,9], 'max_features':[2,4,6,8]},{'bootstrap': [True],'n_estimators':[5],'max_features':[5]},]
forest = RandomForestClassifier(random_state=47563)
grid_search = GridSearchCV(forest,rejilla_parametros,cv=5,scoring='neg_log_loss',return_train_score=True)
grid_search.fit(Conjunto_entrenamiento,objetivo_train)
```

Vemos ahora cuales son los mejores valores de hiperparámetros y por tanto cuál es el mejor modelo de Random Forest:

```{python}
mejor_mod_RF = grid_search.best_estimator_
print(mejor_mod_RF)
```


## Columna {data-width=2 .tabset}

### Métricas del modelo

```{python}
objetivo_predicho_RF = mejor_mod_RF.predict(Conjunto_test)
print(classification_report(objetivo_test,objetivo_predicho_RF,target_names=np.unique(objetivo_test)))
```

### Matriz de confusión

```{python}
ConfusionMatrixDisplay.from_estimator(mejor_mod_RF,Conjunto_test,objetivo_test,display_labels=np.unique(objetivo_test),cmap="Blues")
plt.title("Matriz de Confusión: Método RF")
plt.show()
```
```{r}

```




### Frontera de separación

```{python}
grafica_frontera_decision(mejor_mod_RF,Conjunto_test,objetivo_test,"Frontera decision RF")

```


## Columna {data-width=1}

### Conclusiones
El modelo es bastante mejor que el anterior, ya que tenemos una accuracy casi de 0.9, y la métrica recall en insomnio y apnea del sueño es muy próxima a 1. Pasamos a ver la matriz de confusión también, y nos percatamos que el modelo clasifica perfectamente a las persponas con apnea del sueño y cas perfecto a los sujetos con insomnio. Viendo la frontera de decisión es mucho mejor que en el apartado anterior.

# Modelo Decision Tree {data-navmenu="Modelado de datos"}

## Columna {data-width=1}

### Modelo
Vamos a pasarle al modelo otra vez una serie de hiperparámetros que sera la profundidad máxima del árbol para ver otra vez cual es la mejor profundidad de todas ellas y quedarnos con el mejor modelo:

```{python}
rejilla_parametros =[{'max_depth':[3,5,7,9,11]},]

arbol_decision = DecisionTreeClassifier(random_state=47563)
grid_search=GridSearchCV(arbol_decision,rejilla_parametros,cv=5,scoring='neg_log_loss',return_train_score=True)

grid_search.fit(Conjunto_entrenamiento,objetivo_train)

mejor_mod_DT = grid_search.best_estimator_
```

Vemos ahora cuales son los mejores valores de hiperparámetros y por tanto cuál es el mejor modelo de Decision Tree:

```{python}
print(mejor_mod_DT)
```


## Columna {data-width=2 .tabset}

### Métricas del modelo

```{python}
objetivo_predicho_DT = mejor_mod_DT.predict(Conjunto_test)
print(classification_report(objetivo_test,objetivo_predicho_DT,target_names=np.unique(objetivo_test)))
```

### Matriz de confusión
```{python}
ConfusionMatrixDisplay.from_estimator(mejor_mod_DT,Conjunto_test,objetivo_test,display_labels=np.unique(objetivo_test),cmap="Blues")
plt.title("Matriz de Confusión: Método DT")
plt.show()
```

### Frontera de separación

```{python}
grafica_frontera_decision(mejor_mod_DT,Conjunto_test,objetivo_test,"Frontera decision DT")

```


## Columna {data-width=1}

### Conclusiones
Tenemos un modelo de un rendimiento muy similar al primero a simple vista de las métricas. Volvemos a visualizar la matriz de confusión, y vemos que no clasifica para nada bien a las personas que no tienen enfermedad.

# Modelo KNN {data-navmenu="Modelado de datos"}

## Columna {data-width=1}

### Modelo
```{python}
rejilla_parametros =[{'n_neighbors':[3,5,7,9,11], 'metric':['hamming']},]

knn = neighbors.KNeighborsClassifier(metric='hamming')
grid_search=GridSearchCV(knn,rejilla_parametros,cv=15,scoring='neg_log_loss',return_train_score=True)

grid_search.fit(Conjunto_entrenamiento,objetivo_train)

mejor_mod_knn = grid_search.best_estimator_
```

Vemos ahora cuales son los mejores valores de hiperparámetros y por tanto cuál es el mejor modelo de KNN:

```{python}
print(mejor_mod_knn)
```


## Columna {data-width=2 .tabset}

### Métricas del modelo

```{python}
objetivo_predicho_knn = mejor_mod_knn.predict(Conjunto_test)
print(classification_report(objetivo_test,objetivo_predicho_knn,target_names=np.unique(objetivo_test)))
```

### Matriz de confusión
```{python}
ConfusionMatrixDisplay.from_estimator(mejor_mod_knn,Conjunto_test,objetivo_test,display_labels=np.unique(objetivo_test),cmap="Blues")
plt.title("Matriz de Confusión: Método Knn")
plt.show()
```

### Frontera de separación

```{python}
grafica_frontera_decision(mejor_mod_knn,Conjunto_test,objetivo_test,"Frontera decision Knn")

```


## Columna {data-width=1}

### Conclusiones
En este modelo ocurre todo lo contrario, predecimos todos los pacientes como que tienen insomnio, lo cual es incorrecto. Este modelo no lo elegiremos como el mejor, lo descartamos inmediatamente.

# Modelo MLP {data-navmenu="Modelado de datos"}

## Columna {data-width=1}

### Modelo
```{python}
rejilla_parametros =[{'hidden_layer_sizes':[(5,5),(5,10),(5,15),(10,5),(10,10),(10,15),(15,5),(15,10),(15,15)],'activation':['relu'],'solver':['adam'],'max_iter':[500,1000]},]

mlp = MLPClassifier(random_state=47563)
grid_search=GridSearchCV(mlp,rejilla_parametros,cv=5,scoring='neg_log_loss',return_train_score=True)

grid_search.fit(Conjunto_entrenamiento,objetivo_train)
mejor_mod_mlp = grid_search.best_estimator_
```

Vemos ahora cuales son los mejores valores de hiperparámetros y por tanto cuál es el mejor modelo de mlp:

```{python}
print(mejor_mod_mlp)
```
Nos quedamos con el parámetro con menos nodos en cada capa oculta y menor número de iteraciones. Pasamos a ver las métricas del modelo

## Columna {data-width=2 .tabset}

### Métricas del modelo

```{python}
objetivo_predicho_mlp = mejor_mod_mlp.predict(Conjunto_test)
print(classification_report(objetivo_test,objetivo_predicho_mlp,target_names=np.unique(objetivo_test)))
```

### Matriz de confusión
```{python}
ConfusionMatrixDisplay.from_estimator(mejor_mod_mlp,Conjunto_test,objetivo_test,display_labels=np.unique(objetivo_test),cmap="Blues")
plt.title("Matriz de Confusión: Método Mlp")
plt.show()
```

### Frontera de separación

```{python}
grafica_frontera_decision(mejor_mod_mlp,Conjunto_test,objetivo_test,"Frontera decision Mlp")

```


## Columna {data-width=1}

### Conclusiones
Tenemos un modelo similar al primero de nuevo, aunque algo mejorado. Vemos en la matriz de confusión y nos damos cuenta de que clasificamos con muy poca precisión la clase no enfermedad, a pesar de que es algo mejor para insomnio y apnea del sueño. La frontera de separación es algo menos basta que la del modelo NB, pero sigue siendo poco aclaratoria. Es un modelo calcado al primero, que presenta el mismo problema.

# Elección mejor modelo {data-navmenu="Modelado de datos"}
Hemos visto las métricas de cada uno de los modelos, comparando su *accuracy*, *precission*, ó parámetros como *f1 score*. También hemos observado para cada uno de los modelos la matriz de confusión, y un gráfico en el que vemos como separan las clases las 2 componentes principales. Tras lo comentado en cada uno de los modelos selecciono el modelo **Random Forest**.

# Nuevos pacientes

Introduzca los datos del paciente {.sidebar data-width=400}
--------------------------------------------------

```{r}
selectInput("Sexo", label = "Sexo del paciente:",
            choices = c("Male", "Female"), selected = "Male")
```

```{r}
selectInput(
  "Edad", 
  label = "Edad del paciente:",
  choices =  unique(10:100), 
  selected = first(unique(10:100))
)
```

```{r}
selectInput("Ocupacion", label = "Trabajo del paciente:",
            choices = c("Manual Labor", "Office Worker","Retired","Student"), selected = "Manual Labor")
```

```{r}
selectInput(
  "Horas_sueño", 
  label = "Horas de sueño del paciente (en horas):",
  choices =  unique(seq(3,14,0.1)), 
  selected = first(seq(3,14,0.1))
)
```

```{r}
selectInput(
  "Calidad_sueño", 
  label = "Calidad sueño del paciente (1-10):",
  choices =  unique(1:10), 
  selected = first(1:10)
)
```

```{r}
selectInput(
  "Actividad_Fisica", 
  label = "Actividad física del paciente (minutos al día):",
  choices =  unique(10:200), 
  selected = first(10:200)
)
```

```{r}
selectInput(
  "Nivel_estres", 
  label = "Nivel de estres del paciente (1-10):",
  choices =  unique(1:10), 
  selected = first(1:10)
)
```

```{r}
selectInput("Indice_masa_corporal", label = "Índice de masa corporal del paciente:",
            choices = c("Normal", "Obese", "Overweight", "Underweight"), selected = "Normal")
```

```{r}
selectInput(
  "pulsaciones", 
  label = "Pulsaciones del paciente (por minuto):",
  choices =  unique(30:160), 
  selected = first(30:160)
)
```


```{r}
selectInput(
  "pasos", 
  label = "Pasos diarios del paciente:",
  choices =  unique(1000:16000), 
  selected = first(1000:16000)
)
```

```{r}
selectInput(
  "presion_baja", 
  label = "Presión baja del paciente:",
  choices =  unique(50:110), 
  selected = first(50:110)
)
```

```{r}
selectInput(
  "presion_alta", 
  label = "Presión alta del paciente:",
  choices =  unique(100:160), 
  selected = first(100:160)
)
```

Diagnóstico del paciente
--------------------------------------------------

Según nuestro mejor modelo, el paciente presenta:

```{r,echo=FALSE}
datos_paciente <- reactive({data.frame(
  "Gender" = input$Sexo,
  "Age" = as.numeric(input$Edad),
  "Occupation" = input$Ocupacion,
  "Sleep Duration (hours)"= as.numeric(input$Horas_sueño),
  "Quality of Sleep (scale: 1-10)" = as.numeric(input$Calidad_sueño),
  "Physical Activity Level (minutes/day)" = as.numeric(input$Actividad_Fisica),
  "Stress Level (scale: 1-10)" = as.numeric(input$Nivel_estres),
  "BMI Category" = input$Indice_masa_corporal,
  "Heart Rate (bpm)" = as.numeric(input$pulsaciones),
  "Daily Steps" = as.numeric(input$pasos),
  "Press_High" = as.numeric(input$presion_alta),
  "Press_Low" = as.numeric(input$presion_baja),check.names = F
)})
```

```{python}
import builtins
builtins.pipeline = pipeline
builtins.mejor_mod_RF = mejor_mod_RF
builtins.Conjunto_test = Conjunto_test
```

```{r}
output$diagnostico <- renderPrint({
  datos <- datos_paciente()
  datos_py <- reticulate::r_to_py(datos)
  datos_transformados <- py$pipeline$transform(datos_py)
  prediccion <- py$mejor_mod_RF$predict(datos_transformados)
  cat(prediccion)
})

verbatimTextOutput("diagnostico")
```

Con una probabilidad de:

```{r}
output$prob <- renderPrint({
  datos <- datos_paciente()
  datos_py <- reticulate::r_to_py(datos)
  datos_transformados <- py$pipeline$transform(datos_py)
  probabilidad_pred <- py$mejor_mod_RF$predict_proba(datos_transformados)
  cat(round(max(probabilidad_pred),3))
  #propabilidad_r <- py_to_r(probabilidad_pred)
  #probabilidad_r
})

verbatimTextOutput("prob")
```

